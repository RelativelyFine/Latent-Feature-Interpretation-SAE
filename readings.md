# Mechanistic Interpretability Readings

Below are a list of the readings that will aid you through this project. Reviewing the relevant literature is absolutely necessary before delving into any research project. It can help you examine techniques for work that's already been done in the past, methods that have yielded promising results, and save you from falling down fruitless rabbit holes. While they can seem intimidating at first, understanding as much as you can is certainly more beneficial than foregoing reading them entirely. 

For each paper listed, we want you to write a half page report/summary on the details of the paper. Try your best not to use ChatGPT to do this for you-- You're only cheating yourself out of understanding material that will greatly help you to meaningfully contribute to this project. If you've never read academic papers before, here's a decent guide on how to go through research papers to get you started: https://cspages.ucalgary.ca/~pwlfong/Pub/inroads2009.pdf


Some of the readings below are listed as mandatory. Others are supplementary-- although these are not totally required, it's still a great idea to go through them. 

## Mandatory Reading:

https://www.neelnanda.io/mechanistic-interpretability/getting-started 
For this resource, you can split reading "Getting the fundamentals" between this week and next week.

https://transformer-circuits.pub/2023/monosemantic-features/index.html

https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html

https://arxiv.org/pdf/2406.17759



## Supplementary Readings:

https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J
https://arena3-chapter1-transformer-interp.streamlit.app/%5B1.2%5D_Intro_to_Mech_Interp
https://arxiv.org/abs/2406.11717
https://arxiv.org/pdf/2405.08366



## Fundamentals 

If you have no experience with neural networks whatsoever, this is a really great place to start. In this section I've included some articles and videos explaining basics of multilayer perceptron networks to the ins and outs of the Transformer architecture. 

### Neural Networks
https://www.ibm.com/topics/neural-networks
https://www.youtube.com/watch?v=aircAruvnKk

### Transformers 

https://alok-shankar.medium.com/understanding-googles-attention-is-all-you-need-paper-and-its-groundbreaking-impact-c5237043540a

https://www.youtube.com/watch?v=wjZofJX0v4M

https://www.youtube.com/watch?v=bCz4OMemCcA 
This is a great video which goes through each step of the basic Transformer process. If you're having difficulty understanding things like Key and Query matrices, I highly recommend watching this all the way through.

https://arxiv.org/abs/1706.03762
This is the original paper which introduced the Transformer model.

